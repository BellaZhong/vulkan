Vulkan Sync

vulkan采用异步的方式运行。vulkan同步采用多个同步原语句实现，其中三种主要的同步原语句类型为：
1.fence 栅栏 当主机需要等待设备完成某次提交中的大量工作时使用，通常需要操作系统协助
2.event 事件 由主机或者设备发出，当设备发出信号时，可以在命令缓冲区中通知它，并且在pipeline上的某个点由设备等它
3.semaphore 信号量 用于控制设备上的不同队列对资源的所有权，可用于同步不同队列上可能异步执行的工作

1.fence是中等量级的同步原语句，向fence传递和操作系统交互的命令，如vkQueueSubmit()，当这些命令发起的任务完成的时候，fence会收到信号通知。线程等待fence时，可能会休眠，这是为了等待时间长的操作系统设计的，例如等待多个cmdbuffer执行完毕，渲染到屏幕的时候。
主要作用是防止主机修改正在被设备使用的数据
创建fence对象
VkResult vkCreateFence(
	VkDevice device,
	const VkFenceCreateInfo* pCreateInfo,
	const VkAllocationCallbacks* pAllocator,
	VkFence* pFence
)
device指定创建fence对象的设备
VkFenceCreateInfo是一个结构体，其原型为
typedef struct VkFenceCreateInfo{
	VkStructureType sType;
	const void* pNext;
	VkFenceCreateFlags flags;
}VkFenceCreateInfo

sType = VK_STRUCTURE_TYPE_FENCE_CREATE_INFO
pNext = nullptr
flags是一组标志位，其中一个较为明显的，如果设置VK_FENCE_CREATE_SIGNALED_BIT，则fence初始状态是有信号的，否则，就是无信号的
pAllocator用于指向主机中用于分配fence内存的区域，这里可以为nullptr
成功，会将一个非空的fence写入pFence中

/////////////////////////////////////////////
销毁fence对象释放资源
void vkDestroyFence(
	VkDevice device,
	VKFence fence,
	const VKAllocationCallbacks* pAllocator
)
如果在创建fence的时候没有消耗主机内存，这里的pAllocator应为nullptr
////////////////////////////////////////////

fence可用于任何接受fence的api中，例如
VkResult vkQueueSubmit(
	VkQueue queue,
	uint32_t submitCount,
	const VkSubmitInfo* pSubmits,
	VkFence fence
)

/////////////////////////////////////////////
查询fence状态
VkResult vkGetFenceStatus(
	VkDevice device,
	VkFence fence
)
该API的返回值为VK_SUCCESS，表示当前是有信号的状态，VK_NOT_READY，表示当前是无信号的状态
但是这个api是阻塞式的，所以我们一般会用vkWaitForFences
VkResult vkWaitForFences(
	VkDevice device,
	uint32_t fenceCount,
	const VkFence* pFences,
	VkBool32 waitAll,
	uint64_t timeout
)
该api可以等待任何数量的fence对象，由fenceCount指定，该api要么等待数组pFences中所有fence都变为有信号的状态，要么在任意一个fence变为有信号时返回，如果waitAll是VK_TRUE，则等待全部fence变为有信号状态，否则，就等待任何一个变为有信号状态，这个api就会返回。他的等待可能会耗费很长时间，timeout用于指定超时参数，数值单位为纳秒，64bit，如果在timeout之内没有收到信号改变，则他会返回等待超时，而不是not_ready
VK_SUCCESS，有fence状态变为有信号
VK_TIMEOUT，timeout之内没有fence状态变为有信号

一个fence一旦收到了信号，则会保持这个状态，直到显示的把他设置为无信号的状态。重置由该api完成
VkResult vkResetFences(
	VkDevice device,
	uint32_t fenceCount,
	const VkFence* pFences
)

/////////////////////////////////////////////////////////
事件是一个细粒度的同步原语句，事件有两种状态，有信号和无信号，他不像fence，可由操作系统从一个状态转为另一个状态，只能由设备或者主机显式的向事件发送信号或者进行重置。
创建事件
VkResult vkCreateEvent(
	VkDevice device,
	const VkEventCreateInfo* pCreateInfo,
	const VkAllocationCallbacks* pAllocator,
	VkEvent* pEvent
)

typedef struct VkEventCreateInfo{
	VkStructureType sType;
	const void* pNext;
	VkEventCreateFlags flags
}
sType = VK_STRUCTURE_TYPE_EVENT_CREATE_INFO
pNext = nullptr
flags初始状态应为0
用完事件以后，应由如下api来释放事件对象资源
void vkDestroyEvent(
	VkDevice device,
	VkEvent event,
	const VkAllocationCallbacks* pAllocator
)
主机上改变事件的状态需要调用
VkResult vkSetEvent(
	VkDevice device,
	VkEvent event
)
vkResetEvent负责重置事件的状态
由设备对事件进行设置的api为
void vkCmdSetEvent(
	VkCommandBuffer commandBuffer,
	VkEvent event,
	VkPipelineStageFlags stageMask
)
同样有vkCmdResetEvent和vkGetEventStatus, vkCmdWaitEvents

////////////////////////////////////////////////////
信号量代表了可被硬件以原子方式设置和重置的标记，当设置信号量时，设备会等待他变为未设置状态，设置以后，会将调度权交给调用者。
与另外几个同步的原语句不同的是，信号量不允许你显式的设置，重置或者等待，信号量是用于同步不同队列对资源的访问，从而形成向设备提交完整的工作部分。
例如，在vkQueueSubmit()结构体中，用VkSubmitInfo数组作为输入，这个数组里面包含了两个信号量成员，pWaitSemaphores和pSignalSemaphores，当执行pCommandBuffers里的命令之前，队列会等待pWaitSemaphore里的所有信号量，这样，他就会获取信号量的所有权，接下来，他会执行pCommandBuffers里每一个buffer的命令，执行完后，他会向pSignalSemaphores里的每一个信号量发送信号。可以适用于跨队列命令提交，例如：
首先，提交命令缓冲区到compute队列
VkSubmitInfo computeSubmitInfo = 
{
	VK_STRUCTURE_TYPE_SUBMIT_INFO, //sType
	nullptr, //pNext
	0, //waitSemaphoreCount
	nullptr, //pWaitSemaphores
	nullptr, //pWaitDstStageMask
	1, //commandBufferCount
	&computeCmdBuffer, //pCommandBuffers
	1, //signalSemaphoreCount
	&m_computeToGfxSemaphore //pSignalSemaphores
}
vkQueueSubmit(
	m_computeQueue,
	1,
	&computeSubmitInfo,
	VK_NULL_HANDLE
)
其中pSignalSemaphores就意味着，一旦执行完，这个信号量就会变为有信号的状态
接下来，提交到graphics队列
{
	VK_STRUCTURE_TYPE_SUBMIT_INFO, //sType
	nullptr, //pNext
	0, //waitSemaphoreCount
	&m_computeToGfxSemaphore, //pWaitSemaphores
	&waitStages, //pWaitDstStageMask
	1, //commandBufferCount
	&graphicsCmdBuffer, //pCommandBuffers
	0, //signalSemaphoreCount
	nullptr //pSignalSemaphores
}
vkQueueSubmit(
	m_graphicsQueue,
	1,
	&graphicsSubmitInfo,
	VK_NULL_HANDLE
)
首先，当compute queue中的命令执行完以后，他会向该信号量发送信号，接着，graphics queue中会等待这个信号量变为有信号的状态，这就保证了，graphics queue在使用数据之前，所有的compute queue上的命令都已经执行完毕。


1.所有的Action类命令（Draw、Transfer、Clear、Copy等）以及显示地使用同步机制的命令，这些命令在执行VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT时，会遵循提交顺序。即这些命令开始执行的顺序，是严格遵循提交顺序的。 但这并不意味着这些命令结束执行时的顺序会有什么约束，所有的这些命令，到底是哪个先结束，隐式同步并没有严格的规定，也就是说任何一个命令都有可能最先结束。

2.所有的设置状态类的命令（bind pipelines, descriptor sets, and buffers等），由于它们不需要在GPU上执行，它们只负责设置CPU上相应CommandBuffer的状态，所以它们的执行顺序，遵循它们在CPU上写入CommandBuffer时的顺序。

3.所有的Draw类命令在处理Primitive时，首先遵循提交顺序，即先提交的Draw中的Primitive会先被处理。而在一个Draw内所提交的Primitive，会按照顶点和索引的下标顺序执行。

4.ImageLayout的转移，是通过ImageMemoryBarrier实现的，是一种显式的同步原语，它们遵循提交顺序，即先提交的先转移。


Barriers
VkPipelineStageFlags
Vulkan中并不提供任何命令级别的同步，即明确地指定某两个命令之间需要满足什么同步。所有需要同步的命令，都会将其执行过程划分为若干个阶段，所有的命令都会在流水线上执行，只是不同类型的命令，它们的阶段划分是不同的。当我们在Vulkan中使用同步机制时，都是以流水线阶段为单位，即某个流水线阶段上执行的所有命令，会在当前阶段暂停，等待另一个流水线阶段上的所有命令在相应的阶段执行完全后，再开始执行。VkPipelineStageFlags就代表流水线阶段.

VkAccessFlags
Vulkan中的同步不仅控制操作执行的顺序，还要控制缓存的写回，即内存数据的同步。
不管是CPU还是GPU，存储系统都是按级划分的，比如主存、L2 Cache、L1 Cache等等，假设只有这三级存储结构。从左往右，读写的速率会依次提升，但是价格也会依次增高，所包含的数据量也会依次减少。VkAccessFlags的取值命名都是按照：VK_ACCESS_ + Stage + Resource Read/Write ，代表对内存进行读写，所以VkAccessFlags是为了表达流水线阶段对于内存的读写操作。
每一个这样的Access，都会从某一个L1 Cache上读或写数据，具体地选择哪一个L1 Cache来进行读或写，由驱动决定。假如某一个资源，比如一个Buffer，在某一次Access中被修改了，那么那一次的写操作只会对相应的那个L1 Cache有效果，在此后的某个Access中，需要再读这个Buffer的相关数据，如果只做执行过程间的同步（设置一个同步，让这次的读操作在前一个Access的写操作完成后再执行），这次读到的很有可能就不是这个Buffer的最新的值，因为尽管这次读操作确实是在写操作完成之后才执行的，但是那一次写操作只将数据写到了L1 Cache上，我们需要让这次读操作用到的L1 Cache也要包含的是修改以后得到的值才行。所以你会发现，所有的MemoryBarrier，都要包含VkAccessFlags，对于MemoryBarrier，它所控制的同步执行过程为：
①等待srcStageMask所代表的流水线阶段上的所有操作执行完成
②等待srcAccessMask所代表的内存操作available
③等待相应的available内存对于dstAccessMask所代表的内存操作是visible的
④唤醒dstStageMask所代表的流水线阶段上的所有操作


Vulkan中的所有同步，大体上可以分为两种，一种是操作执行类的同步，即操作执行的先后顺序，另一种是内存类的同步，即让内存数据在各种不同的L1 Cache之间同步，当进行内存数据的显式同步时，都需要用到某一类MemoryBarrier。

还要注意，并不是所有的同步情景一定都得用到内存类的同步，比如读后写问题，这个情景下，只需要控制写操作在读操作之后进行就可以了，读操作不涉及到任何内存的修改，因此不需要将修改以后的内存变得available、visible之类的操作。


VkImageLayout
Vulkan中的同步原语还可以有附加的作用。比如一个VkImageMemoryBarrier，它附带的oldLayout和newLayout参数，可以实现让相应的Image进行Layout的转移。每一个Image都会处于某一个Layout下，一些操作只能在特定的流水线阶段对特定Layout下的Image才能使用，所以我们需要在程序执行过程的每一个阶段细致地设置每一个Image的Layout，Layout的转移就是通过这样的一个同步机制来实现的。为什么Vulkan会将这样一个操作设计在一个同步原语中呢？事实上Layout的转移，无非也就是将相应的Image数据通过不同的压缩、排列等方式经过变换以后写到内存中的其他位置以供特殊的需求使用，即Layout的转移实际就是内存的读写操作，因此它需要用到内存数据的同步。Spec中明确指出，Layout进行转移时，相应的Image的内存一定得是available的，一个ImageMemoryBarrier所包含的同步执行过程为：
①等待srcStageMask所代表的流水线阶段上的所有操作执行完成
②等待srcAccessMask所代表的内存操作available
③进行ImageLayout Transition
④等待相应的available内存对于dstAccessMask所代表的内存操作是visible的
⑤唤醒dstStageMask所代表的流水线阶段上的所有操作

Vulkan中不存在只在一个CommandBuffer内有效的同步机制，所有的同步，在全局上都应该认为是对一个Queue中的所有命令有效果。




Fence
Fence用于同步渲染队列和CPU之间的同步，它有两种状态，signaled和unsignaled。
在创建Fence时可以指定它的初始状态；
在调用vkQueueSubmit时，可以传入一个Fence，这样当Queue中的所有命令都被完成以后，Fence就会被设置成signaled的状态；
通过调用vKResetFences可以让一个Fence恢复成unsignaled的状态；

vkWaitForFences会让CPU在当前位置被阻塞掉，然后一直等待到它接受的Fence变为signaled的状态，这样就可以实现在某个渲染队列内的所有任务被完成后，CPU再执行某些操作的同步情景。

举一个具体的例子：假如现在SwapChain中一共有3个Image，然后创建了3个CommandBuffer分别代表在渲染到相应Image时所需要执行的所有命令。在每一帧渲染时，我们需要获取当前需要渲染到的Image的编号，然后使用对应的CommandBuffer，传入渲染队列中，执行渲染命令。那么现在就有一个问题，一个CommandBuffer，如果它还没有被执行完全，那么它是不能够再次被开始执行的。也就是说上面所说的那个获取CommandBuffer后，把它传入渲染队列执行的这样一个CPU上的操作一定要在这个CommandBuffer在上一次被执行完全以后才可以执行。所以这里就遇到了一个渲染队列和CPU之间的一个同步情景，此时可以对每个CommandBuffer分别设置一个Fence来实现这样的一种同步。


Semaphore
Semaphore用于渲染队列每次提交的一批命令（batch）之间的同步，和Fence一样，它也有两种状态：signaled和unsignaled。
调用vkQueueSubmit提交命令时，会填充VkSubmitInfo结构，而这个结构体中需要填入pWaitSemaphores、pSignalSemaphores、pWaitDstStageMask，表示此次提交的所有命令在执行到pWaitDstStageMask时，要停下，必须要等待pWaitSemaphores所指向的所有Semaphore的状态变成signaled时才可以继续执行，此次提交的所有命令结束以后，pSignalSemaphores所指向的所有Semaphore的状态都会被设置成signaled。

可以看到Fence和Semaphore都会在vkQueueSubmit时作为参数传入，不同之处是，Fence用于阻塞CPU直到Queue中的命令执行结束（CPU、CPU之间的同步），而Semaphore用于不同的命令提交之间的同步（GPU、GPU之间的同步）

在渲染时，需要将渲染的结果写入到ColorAttachment中，我们必须要等待上一次把这个ColorAttachment给present到屏幕上的命令结束以后，才可以完成这个写入操作, 并且，将当前帧渲染结果显示到屏幕上的这个present命令，必须要等到当前帧的render命令完全执行结束以后，才可以开始执行。

和Fence一样，Semaphore也是一种粗粒度的同步，它本身也提供了隐含的内存数据的同步：
1.当让一个semaphore变成signaled时：semaphore之前的所有命令涉及到的内存写操作，都会在semaphore变成signaled之前，达到available的状态
2.当等待一个semaphore变成signaled时：在semaphore变成signaled之后，所有暂停的命令被重新唤醒继续执行之前，所有此后相关的Memory Access，都会达到visible的状态。
也就是说在使用Fence和Semaphore时，一般是不需要对GPU上有关的任何Memory Access做同步处理，这些都会被自动完成。但是，这些隐含的同步只是针对GPU的，CPU上所需要的内存数据同步操作必须由应用程序显式完成，比如：当CPU需要读一个经由GPU修改过的内存数据，就需要加一个MemoryBarrier来确保CPU读到的是最新的数据。

还有一点值得注意的是，在讨论Fence和Semaphore时，都提到了vkQueueSubmit函数，这个函数本身也是隐含了一个内存数据的同步的：就是CPU上所有的内存修改操作，都会在GPU读写之前，对GPU而言变成available的，并且对于所有之后GPU上的MemoryAccess，它们都是visible的。


Event
Event用于同步提交到同一队列的不同命令，或者同步CPU和队列。它同样也具有两种状态——signaled和unsignaled，与Fence不同的是，它的状态改变既可以在CPU上完成，也可以在GPU上完成，并且它是一种细粒度的同步机制。注意：Event不能用于不同队列的命令之间的同步。

在CPU上，可以调用vkSetEvent来使一个Event变成Signaled的状态；可以调用vkResetEvent来使一个Event变成Unsignaled的状态；可以调用vkGetEventStatus来获取一个Event的当前状态，可以利用这个状态来对CPU进行阻塞。

而在GPU上：
1.可以通过vkCmdSetEvent命令来使得一个Event变成Signaled状态，此时该命令附带了一个操作执行同步：根据提交顺序，所有在该命令之前的所有命令都必须在此次把Event设置Signaled状态之前完成。
2.可以通过vkCmdResetEvent命令来使得一个Event变成Unsignaled状态，此时该命令附带了一个操作执行同步：根据提交顺序，所有在该命令之前的所有命令都必须在此次把Event设置Unsignaled状态之前完成。

这里有一点非常需要注意：vkCmdSetEvent和vkCmdResetEvent不能够在一个RenderPass内被执行。


pipeline barrier
它本身定义了一个操作执行的同步
A：在这条命令之前的所有的命令在srcStageMask所指示的stage的操作
B：在这条命令之后的所有的命令在dstStageMask所指示的stage的操作
B一定要在A执行完全后才可以开始执行。
同时后6个参数代表的MemoryBarrier实现内存数据的同步。
可以发现PipelineBarrier和Event非常像，区别在于Event的Signal和Wait可以在两个地方，而PipelineBarrier直接将命令序列一分为二。